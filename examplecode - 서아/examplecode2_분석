####### 꼭 함수 이름 바꿔야 함


# -*- coding: utf-8 -*-

import cv2               # opencv 패키지
import numpy as np
import math

def frame(filename, portal): 
    vid=cv2.VideoCapture(filename) #비디오 보기
    count=0
    while True:
        yes, image=vid.read() #영상을 사진 단위로 받아오기
        if not yes: #영상이 끝나면
            break
        count+=1
        cv2.imwrite(portal+'/'+str(count)+'.png',image) #지정된 경로에 저장
        if count==200:
            break

def info(filename): #[총 프레임 수, fps, 가로, 세로 길이] 리턴
    vid=cv2.VideoCapture(filename)
    temp=[]
    temp.append(int(vid.get(cv2.CAP_PROP_FRAME_COUNT))) #총 프레임 수
    temp.append(int(vid.get(cv2.CAP_PROP_FPS))) #fps
    temp.append(int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))) #가로
    temp.append(int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))) #세로
    return temp


-----------------------------------------------------------------------

>> cv2.VideoCapture(옵션)
   : 영상의 지정한 옵션 속성 반환
1. 카메라, Youtube, web에서 영상 가져올 때
2. 동영상 파일을 읽을 때 

################################################
################################################

> cv2.VideoCapture 예시1 < 
# 일반적으로 이 방식 많이 사용하는 듯

import cv2
import timeit

# 영상 정보 불러오기
video = cv2.VideoCapture('KITTI.mp4')

while True:

    ret, frame = video.read()      # ret = 프레임 읽기를 성공하면 True 값 반환
    
    if ret is True:                                             
        
        cv2.imshow('video',frame)  # cv2.imshow(title, image) : 이미지를 사이즈에 맞게 보여줌

        if cv2.waitKey(1) > 0 :  # cv2.waitKey(time) : 키 입력을 대기, time은 msec시간 단위로 공란 또는 0이면 무한정으로 대기
            break

################################################
################################################

> cv2.VideoCapture 예시2 : 파일에서 받아오기 <

import cv2
import os
 
path = '/home/test/test/data'
filePath = os.path.join(path, "vtest.avi")  # 아마 컴퓨터 내 경로 지정해서 가져오는 듯
print(filePath)

if os.path.isfile(filePath):	# 해당 파일이 있는지 확인
    # os.path.isfile() : 파일 유무 판단
    # 파일이면 True, 아니면 False, 없어도 False 반환

    # 영상 객체(파일) 가져오기
    cap = cv2.VideoCapture(filePath)
else:
    print("파일이 존재하지 않습니다.")  

# 프레임을 정수형으로 형 변환
frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))	# 영상의 넓이(가로) 프레임
frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))	# 영상의 높이(세로) 프레임

# CAP_PROP_FPS: 초당 프레임의 수
# CAP_PROP_ZOOM: 카메라 줌
# CAP_PROP_FRAME_COUNT : 비디오 파일의 총 프레임 수
# CAP_PROP_POS_MSEC : 밀리초 단위로 현재 위치
# CAP_PROP_POS_FRAME : 현재 프레임 번호
# CAP_PROP_EXPOSURE : 노출

# 각 항목 확인할 떄는 'get', 변경할 때는 'set'
# cap.get(cv2.CAP_PROP_FRAME_WIDTH) >> 프레임 폭 반환
# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320) >> 프레임의 폭 320으로 변경


frame_size = (frameWidth, frameHeight)
print('frame_size={}'.format(frame_size))

frameRate = 33   # FPS를 말하는 듯
 
while True:
    # 한 장의 이미지(frame)를 가져오기
    # 영상 : 이미지(프레임)의 연속
    # 정상적으로 읽어왔는지 -> retval
    # 읽어온 프레임 -> frame
    retval, frame = cap.read()
    if not(retval):	# 프레임정보를 정상적으로 읽지 못하면
        break  # while문을 빠져나가기
        
    cv2.imshow('frame', frame)	# 프레임 보여주기
    key = cv2.waitKey(frameRate)  # frameRate msec동안 한 프레임을 보여준다
    
    # 키 입력을 받으면 키값을 key로 저장 -> Esc == 27(아스키코드)
    # Esc 키 누르면 종료됨
    if key == 27:
        break	# while문을 빠져나가기
        
if cap.isOpened():	# 영상 파일(카메라)이 정상적으로 열렸는지(초기화되었는지) 여부
    cap.release()	# 영상 파일(카메라) 사용을 종료
    
cv2.destroyAllWindows()


################################################
################################################

> cv2.VideoCapture 예시3 : 유튜브 에서 받아오기 <

import cv2
import pafy # Youtube 메타 데이터 수집/검색 다운 가능한 라입브러리
# pafy는 m4v, webm 형식의 비디오만 다운로드 (오디오 없음)

url = 'https://www.youtube.com/watch?v=u_Q7Dkl7AIk'
video = pafy.new(url)

print('title = ', video.title)  # 유튜브 영상 제목 출력
print('video.rating = ', video.rating)  # 유튜브 영상 별점정보 출력
print('video.duration = ', video.duration)  # 유튜브 영상 플레이 시간 추력
 
best = video.getbest(preftype='mp4')     # 'webm','3gp'
print('best.resolution', best.resolution)
 
cap=cv2.VideoCapture(best.url)

# cap = cv2.VideoCapture(0) # 0번 카메라
 
# frame 사이즈
frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
              int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
print('frame_size =', frame_size)
 
# 코덱 설정하기
# cv2.VideoWriter 이용해 일련의 프레임 동영상 파일로 저장 가능
# >> 크기와 데이터 타입 같아야함, Fourcc (4-문자 코드, four character code)를 지정해야함
# Fource는 동영상 파일의 코덱, 압축 방식, 색상, 픽셀 포맷 등을 정의하는 정수 값

# cv2.VideoWriter_fourcc(*'DIVX') : DIVX MPEG-4 코덱
# cv2.VideoWriter_fourcc(*'XVID') : XVID MPEG-4 코덱
# cv2.VideoWriter_fourcc(*'FMP4') : FFMPEG MPEG-4 코덱
# cv2.VideoWriter_fourcc(*'X264') : H.264/AVC 코덱
# cv2.VideoWriter_fourcc(*'MJPG') : Motion-JPEG 코덱

# fourcc = cv2.VideoWriter_fourcc(*'DIVX')  # ('D', 'I', 'V', 'X')
fourcc = cv2.VideoWriter_fourcc(*'XVID')
 

# cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor=None) 
# isColor : 컬러 영상이면 True, 그렇지 않으면 False, 기본값은 True
# 이미지 저장하기 위한 영상 파일 생성
out1 = cv2.VideoWriter('./data/record0.mp4',fourcc, 20.0, frame_size)
out2 = cv2.VideoWriter('./data/record1.mp4',fourcc, 20.0, frame_size, isColor=False)
 
while True:
    retval, frame = cap.read()	# 영상을 한 frame씩 읽어오기
    if not retval:
        break   
        
    out1.write(frame)	# 영상 파일에 저장   
    
    # 이미지 컬러 변환
    # https://076923.github.io/posts/Python-opencv-10/ # 색상 공간 변환 관련
    # (원본 이미지 색상 공간)2(결과 이미지 색상 공간) 에 색상 공간 코드 조합해 사용 
    # BGR2GRAY : Blue, Green, Red 채널 이미지를 단일 채널, 크레이스케일 이미지로 변경
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    out2.write(gray)	# 영상 파일에 저장 (영상 데이터만 저장, 소리는 X 인듯)      
    
    cv2.imshow('frame',frame)	# 이미지 보여주기
    cv2.imshow('gray',gray)      
    
    key = cv2.waitKey(25)
    if key == 27:      # Esc 키 누르면 강제 종료
        break
        
cap.release()	# 객체 해제
out1.release()
out2.release()
cv2.destroyAllWindows()


------------------------------------------------------------------------



def sub(a,b):    # 단순한 빼기(-) 함수
    if a>=b:
        return int(a-b)
    return int(b-a)

# gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) >> 이용하면 굳이 함수 생성 X 될 듯
def grayscale(img): # 흑백이미지로 변환  
    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

# canny 알고리즘은 Edge 찾기 알고리즘 (윤곽선 따기)
def canny(img, low_threshold, high_threshold): # Canny 알고리즘
    return cv2.Canny(img, low_threshold, high_threshold)

# 흐림 효과를 주는 GaussianBlur () blur 와 차이 )
# GaussianBlur는 전체적으로 밀돠 동일한 노이즈, 백색 노이즈 제거하는데 효과적
# cv2.GaussianBlur(src, ksize, sigmaX, dst=None, sigmaY=None, borderType=None)
### 추가 ) Blur는 경계선이 흐려지는 반면 bilateralFilter는 경계선 유지
### cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace, dst=None, borderType=None)
def gaussian_blur(img, kernel_size): # 가우시안 필터
    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)


# ROI : 이미지 상에서 내가 관심있어하는 일부 영역
def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅

    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지 (0으로 가득찬 ARRAY)


    # 채널 색상공간 구분,,? 각 RGB 분리해 단일 채널로 만들 수 있다고 함
    if len(img.shape) > 2: # Color 이미지(3채널)라면 :
        color = color3
    else: # 흑백 이미지(1채널, 단일채널)라면 :
        color = color1

    # fillPoly : 채워진 다각형 그리기
    # cv2.fillPoly(img, pts, color[, lineType[, shift[, offset]]]) 
    # pts : 좌표 점들 (x,y) / 여기에 다각형 배열 값을 여러 개 입력 가능 
    # https://copycoding.tistory.com/150 (예시)
    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움
    cv2.fillPoly(mask, vertices, color)

    # cv2.bitwise_and : 이미지 비트연산
    # https://copycoding.tistory.com/156 (예시)
    # 이미지와 color로 채워진 ROI를 합침
    ROI_image = cv2.bitwise_and(img, mask)
    return ROI_image


    # 허프 변환은 이미지에서 모양을 찾는 방법 중 하나
    # cv2.HoughLines : 허프 선 변환
    # cv2.HoughLinesP(img, rho, theta, threshold, lines, minLineLength, maxLineGap) : 확률적 허프 선 변환
    # 허프 선 검출 연산량 너무 많아 개선한 것이 확률적 허프 선 변환
    # -> 무작위로 선정한 픽셀에 대해 허프 변환 수행, 점차 그 수를 증가시키는 방법

    # rho : 거리 측정 해상도, 0~1
    # theta : 각도, 라디안 단위 (np.pi/0~180)
    # threshold: 직선으로 판단할 최소한의 동일 개수 (작은 값: 정확도 감소, 검출 개수 증가 / 큰 값: 정확도 증가, 검출 개수 감소)
    # lines : 검출된 선 좌표, N x 1 x 4 배열 (x1, y1, x2, y2)
    # minLineLength(optional) : 선으로 인정할 최소 길이
    # maxLineGap(optional) : 선으로 판단할 최대 간격
    
def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): # 허프 변환
    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)
    #line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)
    #draw_lines(line_img, lines)

    return lines



def doit(newmap,frcount,ROI_range):
    chaseon=[]
    for i in range(1,frcount+1):
        image = cv2.imread(newmap+"/"+str(i)+'.png') # 이미지 읽기
        height, width = image.shape[:2] # 이미지 높이, 너비


        gray_img = grayscale(image) # 흑백이미지로 변환
        # 아니면 cv2.imread('~~.jpg', cv2.IMREAD_GRAYSCALE) 이용해서 바로 읽어올 수도 있음

        blur_img = gaussian_blur(gray_img, 3) # Blur 효과

        canny_img = canny(blur_img, 50, 160) # Canny edge 알고리즘

        # vertices : ROI 구역으로 할 좌표 점
        # np.int32 정수형 / np.float64 실수형
        # region_of_interest -> ROI 구역 만드는 함수
        vertices = np.array([ROI_range], dtype=np.int32)
        ROI_img = region_of_interest(canny_img, vertices)

        # np.squeeze : 크기가 1인 axis 제거
        line_arr = hough_lines(ROI_img, 1, 1 * np.pi/180, 30, 10, 20) # 허프 변환   #[x1, y1, x2, y2]
        line_arr = np.squeeze(line_arr)

        # 기울기 구하기
        # np.arctan2 : 출력 범위가 [-pi, pi] -> 일반 arctan는 180도 이상 차이나는 값 구분 X 때문
        slope_degree = (np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180) / np.pi

        # 수평 기울기 제한
        line_arr = line_arr[np.abs(slope_degree)<160]
        slope_degree = slope_degree[np.abs(slope_degree)<160]
        # 수직 기울기 제한
        line_arr = line_arr[np.abs(slope_degree)>95]
        slope_degree = slope_degree[np.abs(slope_degree)>95]
        # 필터링된 직선 버리기
        L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]
        L_lines, R_lines = L_lines[:,None], R_lines[:,None]
        for j in L_lines:
            for k in j:
                for l in k:
                    l=int(l)
        for j in R_lines:
            for k in j:
                for l in k:
                    l=int(l)
        temp1=[list(j) for j in L_lines]+[list(j) for j in R_lines]
        rrealtemp=[]
        temp2=[]
        for j in temp1:
            for k in j:
                for l in k:
                    rrealtemp.append(int(l))
                temp2.append(rrealtemp)
                rrealtemp=[]
        chaseon.append(temp2)
    return chaseon  #3차


    # 영상처리에서 delta는 영상 기본 밝기 값으로 전체 픽셀 값 조정
    # cv2.imshow("delta0",delta0) 
    # 이 delta가 아닌 것 같고 다른 기울기 인듯 ?

def gradient(a): # 기울기
    g=(a[3]-a[1])/(a[2]-a[0])   # delta y/ delta x
    return g


def analcoc(chaseon):
    count=0
    for j in chaseon:
        for i in j:
            if i==[]:
                continue
            a=gradient(i)
            if abs(a)>math.tan(1.48): # 차선의 기울기가 85도를 넘어가면
                count+=1
                if count==5: # 5프레임 이상 지속되면
                    return 'yes' # 차선 변경이 있었다
    return 'no'  # 차선 변경이 없었다


def SAM_572(search_range,newmap,aV,a):  #search_range=[[a1,b1],[a2,b1],[a3,b2],[a4,b2],[기울기, y절편],[기울기, y절편]]
    av=aV
    temp1=[0,0,0]  # 왼쪽
    temp2=[0,0,0]  # 오른쪽
    temp=[]
    left=search_range[4]   # [기울기, y절편]
    right=search_range[5]   # [기울기, y절편] 
    img=cv2.imread(newmap+"/"+str(a)+".png")  # 이미지 불러오기
    for k in range(search_range[0][1],search_range[2][1]): # 각각의 행
        for j in range(int((k-left[1])/left[0]),int(((k-left[1])/left[0]+int(k-right[1])/right[0])//2)):#왼쪽 부분
            for h in range(3):
                temp1[h]+=int(img[k][j][h]) #BGR값 모두 합하기
        for j in range(int(((k-left[1])/left[0]+(k-right[1])/right[0])/2),int((k-right[1])/right[0]+1)): #오른쪽 부분
            for h in range(3):
                temp2[h]+=int(img[k][j][h]) #BGR값 모두 합하기
    for h in range(3):
        temp1[h]=temp1[h]//((search_range[1][0]-search_range[0][0]+search_range[3][0]-search_range[2][0])*(search_range[2][1]-search_range[0][1])//4)  #평균 내기
        temp2[h]=temp2[h]//((search_range[1][0]-search_range[0][0]+search_range[3][0]-search_range[2][0])*(search_range[2][1]-search_range[0][1])//4)
    temp.append(temp1)
    temp.append(temp2)
    av.append(temp)
    return av




def hoit(search_range,newmap,av,inf):
    left_count=0
    right_count=0
    av=SAM_572(search_range,newmap,av,1)
    start=av[1]  # 처음 내 앞의 상
    for i in range(2,inf[0]+1):
        av=SAM_572(search_range,newmap,av,i)
        if sub(av[i][0][0],start[0][0])+sub(av[i][0][1],start[0][1])+sub(av[i][0][2],start[0][2])>=40: #BGR 값의 변화
            left_count+=1 
        if sub(av[i][1][0],start[1][0])+sub(av[i][1][1],start[1][1])+sub(av[i][1][2],start[1][2])>=40: #BGR값의 변화
            right_count+=1
        if sub(av[i][0][0],start[0][0])+sub(av[i][0][1],start[0][1])+sub(av[i][0][2],start[0][2])<40 and left_count!=0:
            left_count=0
        if sub(av[i][1][0],start[1][0])+sub(av[i][1][1],start[1][1])+sub(av[i][1][2],start[1][2])<40 and right_count!=0:
            right_count=0
        if left_count>=3 and right_count>=3:
            return ('no',i)
        if left_count==5:
            return ('left',i)
        if right_count==5:
            return ('right',i)
    return ('no',0)
    
def makesr(chaseon,ROI_range,inf):
    search_range=[0,0,0,0]
    left=[0,0] # 기울기, y절편   # 왼쪽 차선
    right=[0,0] # 오른쪽 차선
    left[0]=gradient(chaseon[0][0])  # 왼쪽 기울기
    right[0]=gradient(chaseon[0][-1])  # 오른쪽 기울기
    left[1]=chaseon[0][0][1]-left[0]*chaseon[0][0][0]
    right[1]=chaseon[0][-1][1]-right[0]*chaseon[0][-1][0]
    b1=ROI_range[0][1]+inf[3]//12  # 도로인 첫 y지점에서 적당히 밑으로
    a1=(b1-left[1])/left[0]  # 왼쪽 차선에 접하게
    a2=(b1-right[1])/right[0]  # 오른쪽 차선에 접하게
    b2=ROI_range[3][1]-inf[3]//12   # 도로인 마지막 y지점에서 적당히 위
    a3=(b2-left[1])/left[0]  # 왼쪽 차선에 접하게
    a4=(b2-right[1])/right[0]  # 오른쪽 차선에 접하게
    
    
    search_range[0]=[a1,b1]
    search_range[1]=[a2,b1]
    search_range[2]=[a3,b2]
    search_range[3]=[a4,b2]
    search_range.append(left)
    search_range.append(right)
    
    road=[0,0,0,0]
    y2=ROI_range[3][1]-inf[3]//30
    y1=ROI_range[3][1]-inf[3]//15
    x1=(y1-left[1])/left[0]+20  # 왼쪽 차선에 접하게
    x2=(y1-right[1])/right[0]-20  # 오른쪽 차선에 접하게
    x3=(y2-left[1])/left[0]+20  # 왼쪽 차선에 접하게
    x4=(y2-right[1])/right[0]-20  # 오른쪽 차선에 접하게
    road[0]=[x1,y1]
    road[1]=[x2,y1]
    road[2]=[x3,y2]
    road[3]=[x4,y2]
    
    return (search_range,road)

def roadcolor(newmap,road):
    cnt=1
    road_color=[0,0,0]
    while True:
        img=cv2.imread(newmap+'/'+str(cnt)+'.png')
        for i in range(road[2][0]+5,road[3][0]-5):
            road_color[0]+=img[i][road[2][1]][0]
            road_color[1]+=img[i][road[2][1]][1]
            road_color[2]+=img[i][road[2][1]][2]
        road_color[0]=road_color[0]//(road[3][0]-road[2][0])
        road_color[1]=road_color[0]//(road[3][0]-road[2][0])
        road_color[2]=road_color[0]//(road[3][0]-road[2][0])
        if road_color[0]<150 and road_color[1]<150 and road_color[2]<150:
            return road_color
        cnt+=1
        
        